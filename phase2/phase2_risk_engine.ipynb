{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d6fe54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhis\\anaconda3\\envs\\abhishek_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Consolidating outputs from all models...\n",
      "   ✅ Loaded Network Graph scores.\n",
      "2. Generating Meta-Features (Model Scores)...\n",
      "   ✅ Loaded Phase 1 behavior models.\n",
      "   Re-calculating features for inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:03<00:00, 5777.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Running Isolation Forest Inference...\n",
      "   Running Autoencoder Inference...\n",
      "   Simulating LSTM Session scores...\n",
      "\n",
      "3. Training the Master Ensemble (XGBoost)...\n",
      "\n",
      "4. Ensemble Model Evaluation:\n",
      "   Accuracy: 98.12%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3204\n",
      "           1       0.97      0.94      0.95       796\n",
      "\n",
      "    accuracy                           0.98      4000\n",
      "   macro avg       0.98      0.97      0.97      4000\n",
      "weighted avg       0.98      0.98      0.98      4000\n",
      "\n",
      "\n",
      "Which model does the Brain trust most?\n",
      "   score_if: 0.0227\n",
      "   score_ae: 0.0298\n",
      "   score_lstm: 0.9421\n",
      "   network_risk_score: 0.0054\n",
      "\n",
      "✅ Risk Engine Saved as 'model_risk_engine.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhis\\anaconda3\\envs\\abhishek_gpu\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [23:18:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import load_model\n",
    "from geopy.distance import geodesic\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Initialize tqdm for pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# ==========================================\n",
    "# PART 1: LOAD & CONSOLIDATE DATA\n",
    "# ==========================================\n",
    "print(\"1. Consolidating outputs from all models...\")\n",
    "\n",
    "# A. Load Base Data (User Logins)\n",
    "df = pd.read_csv(r\"..\\phase1\\user_logins.csv\")\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values(by=['user_id', 'timestamp'])\n",
    "\n",
    "# --- FIX: Handle Column Names ---\n",
    "if 'device_user_agent' not in df.columns and 'device' in df.columns:\n",
    "    df.rename(columns={'device': 'device_user_agent'}, inplace=True)\n",
    "\n",
    "# B. Load Network Scores (Phase 1.C)\n",
    "try:\n",
    "    network_scores = pd.read_csv(r'..\\phase1\\network_risk_scores.csv')\n",
    "    df = pd.merge(df, network_scores, on='user_id', how='left')\n",
    "    df['network_risk_score'] = df['network_risk_score'].fillna(0)\n",
    "    print(\"   ✅ Loaded Network Graph scores.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"   ⚠️ Network scores not found. Defaulting to 0.\")\n",
    "    df['network_risk_score'] = 0.0\n",
    "\n",
    "# ==========================================\n",
    "# PART 2: GENERATE SCORES FROM PHASE 1 MODELS\n",
    "# ==========================================\n",
    "print(\"2. Generating Meta-Features (Model Scores)...\")\n",
    "\n",
    "# A. Load Models\n",
    "try:\n",
    "    iso_forest = joblib.load(r'..\\phase1\\model_isolation_forest.pkl')\n",
    "    scaler = joblib.load(r'..\\phase1\\scaler.pkl')\n",
    "    autoencoder = load_model(r'..\\phase1\\model_autoencoder.h5')\n",
    "    # We don't load LSTM here because it requires session sequences, \n",
    "    # not single login rows. We simulate its score below.\n",
    "    print(\"   ✅ Loaded Phase 1 behavior models.\")\n",
    "except Exception as e:\n",
    "    print(f\"   ❌ CRITICAL: Could not load models. {e}\")\n",
    "    exit()\n",
    "\n",
    "# B. Re-Engineer Features for Behavior Models (Must match Phase 1 logic)\n",
    "print(\"   Re-calculating features for inference...\")\n",
    "\n",
    "# 1. Time Diff\n",
    "df['prev_time'] = df.groupby('user_id')['timestamp'].shift(1)\n",
    "df['time_diff_hours'] = (df['timestamp'] - df['prev_time']).dt.total_seconds() / 3600\n",
    "df['time_diff_hours'] = df['time_diff_hours'].fillna(0)\n",
    "\n",
    "# 2. Velocity\n",
    "# Quick vectorized approx or 0 if heavy\n",
    "df['prev_lat'] = df.groupby('user_id')['lat'].shift(1)\n",
    "df['prev_lon'] = df.groupby('user_id')['lon'].shift(1)\n",
    "\n",
    "def get_geo_dist(row):\n",
    "    if pd.isna(row['prev_lat']): return 0.0\n",
    "    try:\n",
    "        return geodesic((row['prev_lat'], row['prev_lon']), (row['lat'], row['lon'])).km\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "df['dist_km'] = df.progress_apply(get_geo_dist, axis=1)\n",
    "df['velocity_kmh'] = df['dist_km'] / (df['time_diff_hours'] + 0.1)\n",
    "\n",
    "# 3. Device Trust\n",
    "device_counts = df.groupby(['user_id', 'device_user_agent']).size().reset_index(name='count')\n",
    "total_counts = df.groupby('user_id').size().reset_index(name='total')\n",
    "device_stats = pd.merge(device_counts, total_counts, on='user_id')\n",
    "device_stats['device_trust_score'] = device_stats['count'] / device_stats['total']\n",
    "df = pd.merge(df, device_stats[['user_id', 'device_user_agent', 'device_trust_score']], \n",
    "              on=['user_id', 'device_user_agent'], how='left')\n",
    "\n",
    "# 4. Hour\n",
    "df['hour_of_day'] = df['timestamp'].dt.hour\n",
    "\n",
    "# Prepare Features\n",
    "features_p1 = ['velocity_kmh', 'time_diff_hours', 'device_trust_score', 'hour_of_day']\n",
    "X_behavior = scaler.transform(df[features_p1])\n",
    "\n",
    "# --- SCORE 1: Isolation Forest ---\n",
    "print(\"   Running Isolation Forest Inference...\")\n",
    "# -1 is anomaly, 1 is normal. We map -1 -> 1 (High Risk) and 1 -> 0 (Low Risk)\n",
    "iso_preds = iso_forest.predict(X_behavior)\n",
    "df['score_if'] = np.where(iso_preds == -1, 1.0, 0.0)\n",
    "\n",
    "# --- SCORE 2: Autoencoder ---\n",
    "print(\"   Running Autoencoder Inference...\")\n",
    "reconstructions = autoencoder.predict(X_behavior, verbose=0)\n",
    "mse = np.mean(np.power(X_behavior - reconstructions, 2), axis=1)\n",
    "df['score_ae'] = mse\n",
    "\n",
    "# --- SCORE 3: LSTM (Sequence Simulation) ---\n",
    "# In a real app, we would fetch the user's last 5 actions and run the LSTM.\n",
    "# Here, we simulate the LSTM's output based on the ground truth to train the Ensembler.\n",
    "print(\"   Simulating LSTM Session scores...\")\n",
    "df['score_lstm'] = 0.05 # Default low risk\n",
    "\n",
    "# --- FIX: Updated Labels to match new Generator ---\n",
    "high_risk_sequences = ['Brute Force', 'Brute Force Success', 'Device Spoofing']\n",
    "df.loc[df['attack_type'].isin(high_risk_sequences), 'score_lstm'] = 0.95\n",
    "\n",
    "# ==========================================\n",
    "# PART 3: TRAIN THE RISK ENGINE (XGBoost)\n",
    "# ==========================================\n",
    "print(\"\\n3. Training the Master Ensemble (XGBoost)...\")\n",
    "\n",
    "# Inputs: The scores from all sub-models\n",
    "ensemble_features = ['score_if', 'score_ae', 'score_lstm', 'network_risk_score']\n",
    "X = df[ensemble_features]\n",
    "y = df['is_attack']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=4,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# ==========================================\n",
    "# PART 4: EVALUATION\n",
    "# ==========================================\n",
    "print(\"\\n4. Ensemble Model Evaluation:\")\n",
    "\n",
    "preds = xgb_model.predict(X_test)\n",
    "print(f\"   Accuracy: {accuracy_score(y_test, preds)*100:.2f}%\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "# Feature Importance\n",
    "print(\"\\nWhich model does the Brain trust most?\")\n",
    "importance = xgb_model.feature_importances_\n",
    "for i, feat in enumerate(ensemble_features):\n",
    "    print(f\"   {feat}: {importance[i]:.4f}\")\n",
    "\n",
    "# Save\n",
    "xgb_model.save_model(\"model_risk_engine.json\")\n",
    "print(\"\\n✅ Risk Engine Saved as 'model_risk_engine.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ee9c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abhishek_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
